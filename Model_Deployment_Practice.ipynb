{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6bda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import streamlit as st\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c081649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0              5.1           3.5            1.4           0.2        0\n",
       "1              4.9           3.0            1.4           0.2        0\n",
       "2              4.7           3.2            1.3           0.2        0\n",
       "3              4.6           3.1            1.5           0.2        0\n",
       "4              5.0           3.6            1.4           0.2        0\n",
       "..             ...           ...            ...           ...      ...\n",
       "145            6.7           3.0            5.2           2.3        2\n",
       "146            6.3           2.5            5.0           1.9        2\n",
       "147            6.5           3.0            5.2           2.0        2\n",
       "148            6.2           3.4            5.4           2.3        2\n",
       "149            5.9           3.0            5.1           1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "\n",
    "# Predictor columns\n",
    "X = data.data\n",
    "\n",
    "# Target column\n",
    "y = data.target\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame(X, columns=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']) \n",
    "df['Species'] = data.target\n",
    "\n",
    "# Print dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78030a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   SepalLengthCm  150 non-null    float64\n",
      " 1   SepalWidthCm   150 non-null    float64\n",
      " 2   PetalLengthCm  150 non-null    float64\n",
      " 3   PetalWidthCm   150 non-null    float64\n",
      " 4   Species        150 non-null    int32  \n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 5.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c11e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces target class codes with text\n",
    "df['Species'] = df['Species'].replace([0, 1, 2], ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6c49ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   SepalLengthCm  150 non-null    float64\n",
      " 1   SepalWidthCm   150 non-null    float64\n",
      " 2   PetalLengthCm  150 non-null    float64\n",
      " 3   PetalWidthCm   150 non-null    float64\n",
      " 4   Species        150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9d42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor and target variables\n",
    "X = df.drop('Species', axis=1)\n",
    "y = df['Species']\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8673fe56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline for scaling and logistic regression model\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the dataset\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15922e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-setosa'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the pipeline using data from the same dataset\n",
    "example = pd.DataFrame([[5.1, 3.5, 1.4, 0.2]])\n",
    "example.columns = X.columns\n",
    "pipe.predict(example)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6f3ea3-4b35-45b9-a504-c0c36d755fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ff412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the pipeline\n",
    "import joblib\n",
    "\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    joblib.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75ed0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for Google Cloud Function\n",
    "# All of this code would need to be written in a file called main.py:\n",
    "\n",
    "import json\n",
    "#​\n",
    "def iris_prediction(sepal_length, \n",
    "                    sepal_width, \n",
    "                    petal_length, \n",
    "                    petal_width,\n",
    "                    features):\n",
    "    \"\"\"\n",
    "    Given sepal length, sepal width, petal length, and petal width,\n",
    "    predict the class of iris\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the model from the file\n",
    "    with open(\"model.pkl\", \"rb\") as f:\n",
    "        model = joblib.load(f)\n",
    "        \n",
    "    # Construct the 2D matrix of values that .predict is expecting\n",
    "    X = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "    \n",
    "    data = pd.DataFrame(X)\n",
    "    data.columns = features\n",
    "    \n",
    "    # Get a list of predictions and select only 1st\n",
    "    predictions = model.predict(data)\n",
    "    prediction = predictions[0]\n",
    "    \n",
    "    return {\"predicted_class\": prediction}\n",
    "#​\n",
    "def predict(request):\n",
    "    \"\"\"\n",
    "    `request` is an HTTP request object that will automatically be passed\n",
    "    in by Google Cloud Functions\n",
    "    \n",
    "    You can find all of its properties and methods here:\n",
    "    https://flask.palletsprojects.com/en/1.0.x/api/#flask.Request\n",
    "    \"\"\"\n",
    "    # Get the request data from the user in JSON format\n",
    "    request_json = request.get_json()\n",
    "    \n",
    "    # We are expecting the request to look like this:\n",
    "    # {\"sepal_length\": <x1>, \"sepal_width\": <x2>, \"petal_length\": <x3>, \"petal_width\": <x4>}\n",
    "    # Send it to our prediction function using ** to unpack the arguments\n",
    "    result = iris_prediction(**request_json)\n",
    "    \n",
    "    # Return the result as a string with JSON format\n",
    "    return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edaa18ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 13:57:53.074 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\USER PC\\anaconda3\\envs\\stream-env\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "# import streamlit as st\n",
    "# import pickle \n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "with open('model.pkl','rb') as file:\n",
    "    model_new = pickle.load(file)\n",
    "\n",
    "\n",
    "s_p_l = st.number_input('Sepal Length')\n",
    "s_p_w = st.number_input('Sepal Width')\n",
    "p_t_l = st.number_input('Petal Length')\n",
    "p_t_w = st.number_input('Petal Width')\n",
    "\n",
    "if st.button(\"predict\"):\n",
    "    data = {\n",
    "        \"SepalLengthCm\":[s_p_l],\n",
    "        \"SepalWidthCm\":[s_p_w],\n",
    "        \"PetalLengthCm\":[p_t_l],\n",
    "        \"PetalWidthCm\":[p_t_w]  \n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    pred = model_new.predict(df)\n",
    "    \"\"\"\n",
    "    ## Inputs\n",
    "    \"\"\"\n",
    "    df\n",
    "\n",
    "    \"\"\"\n",
    "    ## Predicted Class\n",
    "    \"\"\"\n",
    "\n",
    "    pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55767430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.write(\"\"\"\n",
    "Below are our sales predictions for this customer\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10716cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "st.write(\"Here's our first attempt at using data to create a table:\")\n",
    "st.write(pd.DataFrame({\n",
    "    'first column': [1, 2, 3, 4],\n",
    "    'second column': [10, 20, 30, 40]\n",
    "}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stream-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
